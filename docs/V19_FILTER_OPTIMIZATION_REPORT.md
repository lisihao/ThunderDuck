# ThunderDuck V19 Filter 优化报告

> **测试日期**: Jan 27 2026 21:10
> **平台**: Apple M4 Max (10 核心)
> **版本**: V19 = 两阶段并行 + 无缓冲区直写 (8T)
> **测试配置**: iterations=15, warmup=2, IQR 剔除异常值

---

## 一、执行摘要

V19 Filter 通过两阶段并行算法，成功将性能从 **0.82x vs DuckDB** 提升到 **2.07x vs DuckDB**。

### 性能对比

| 版本 | 设备 | 时间(ms) | 带宽(GB/s) | vs DuckDB | vs V3 | 正确性 |
|------|------|----------|------------|-----------|-------|--------|
| DuckDB | CPU | 3.004 | 13.32 | 1.00x | - | PASS |
| V3 (template) | CPU SIMD | 3.836 | 10.43 | 0.78x | 1.00x | PASS |
| V4 (GPU AUTO) | Metal | 1.912 | 20.92 | 1.57x | 2.00x | PASS |
| V15 (parallel) | CPU 4T | 3.295 | 12.14 | 0.91x | 1.16x | PASS |
| **V19 (2-phase 8T)** | **CPU 8T** | **1.446** | **27.67** | **2.07x** | **2.65x** | PASS |

---

## 二、问题分析

### 2.1 V15 (0.82x) 的瓶颈

V15 采用简单的多线程分块处理，存在以下问题：

1. **线程创建开销**: 每次调用创建/销毁线程（约 100us 开销）
2. **临时缓冲区**: 每线程分配临时缓冲区存储结果
3. **结果合并**: 最终需要将所有线程的结果复制到输出数组
4. **线程数不足**: 仅使用 4 线程，未充分利用 M4 Max 10 核心

### 2.2 性能公式

对于 10M 数据、50% 选择率的 Filter：
```
V15 开销 = 线程创建 + 输入遍历 + 缓冲区写入 + 结果合并
         ≈ 100us + 数据访问 + 2x 写入
```

---

## 三、V19 优化方案

### 3.1 两阶段算法

```
阶段 1: 并行统计 (8T)
├── Thread 0: count_matches(chunk_0) → n0
├── Thread 1: count_matches(chunk_1) → n1
├── ...
└── Thread 7: count_matches(chunk_7) → n7

计算前缀和: offsets = [0, n0, n0+n1, ...]

阶段 2: 并行直写 (8T)
├── Thread 0: write_matches(chunk_0, output + offset[0])
├── Thread 1: write_matches(chunk_1, output + offset[1])
├── ...
└── Thread 7: write_matches(chunk_7, output + offset[7])
```

### 3.2 核心优化点

| 优化 | V15 | V19 | 收益 |
|------|-----|-----|------|
| 线程数 | 4T | 8T | +100% 并行度 |
| 临时缓冲区 | 有 | 无 | 减少内存分配 |
| 结果合并 | 需要 | 不需要 | 消除复制开销 |
| 数据遍历 | 1 次 | 2 次 | 换取无锁直写 |

### 3.3 关键代码

```cpp
// 阶段 1: 并行统计
template<CompareOp Op>
size_t count_matches_chunk(const int32_t* input,
                           size_t start, size_t end,
                           int32_t value) {
    int32x4_t threshold = vdupq_n_s32(value);
    size_t count = 0;

    for (size_t i = start; i + 64 <= end; i += 64) {
        __builtin_prefetch(input + i + 256, 0, 0);

        #pragma unroll
        for (int g = 0; g < 16; ++g) {
            int32x4_t data = vld1q_s32(input + i + g * 4);
            uint32x4_t mask = simd_compare_i32<Op>(data, threshold);
            count += __builtin_popcount(extract_mask_4(mask));
        }
    }
    return count;
}

// 阶段 2: 直写输出
template<CompareOp Op>
void write_matches_chunk(const int32_t* input,
                         size_t start, size_t end,
                         int32_t value,
                         uint32_t* output,
                         size_t write_offset) {
    // 每个线程知道自己的写入起始位置
    // 无需原子操作或锁
    size_t out_idx = write_offset;
    // ... SIMD 遍历并直接写入 output[out_idx++]
}
```

---

## 四、性能分析

### 4.1 带宽利用率

| 版本 | 带宽(GB/s) | M4 Max 理论带宽 | 利用率 |
|------|------------|-----------------|--------|
| DuckDB | 13.32 | ~400 GB/s | 3.3% |
| V3 | 10.43 | ~400 GB/s | 2.6% |
| V4 GPU | 20.92 | ~400 GB/s | 5.2% |
| V15 | 12.14 | ~400 GB/s | 3.0% |
| **V19** | **27.67** | **~400 GB/s** | **6.9%** |

### 4.2 为什么 V19 比 GPU 更快？

| 因素 | GPU (V4) | CPU 8T (V19) |
|------|----------|--------------|
| 数据传输 | 需要 GPU 缓冲区 | 直接访问内存 |
| 启动延迟 | Metal API 开销 | 线程创建低开销 |
| 选择率处理 | 原子操作竞争 | 无锁直写 |
| 适用场景 | 超大数据量 | 中等数据量 (10M) |

---

## 五、版本演进

| 版本 | 时间(ms) | vs DuckDB | 主要特性 |
|------|----------|-----------|----------|
| V3 | 3.836 | 0.78x | SIMD 模板特化 |
| V4 | 1.912 | 1.57x | GPU 加速 |
| V15 | 3.295 | 0.91x | 4T 并行 |
| **V19** | **1.446** | **2.07x** | **两阶段 8T 直写** |

---

## 六、下一步优化方向

1. **线程池复用**: 静态线程池避免反复创建线程
2. **更大数据量测试**: 100M、1B 数据量验证扩展性
3. **GPU 混合**: 超大数据量时 GPU 可能更优
4. **其他算子应用**: 将两阶段模式应用于 GROUP BY、JOIN

---

## 七、结论

V19 Filter 通过两阶段并行算法，成功实现了：
- **2.07x vs DuckDB** 性能提升
- **2.65x vs V3** 性能提升
- **27.67 GB/s** 内存带宽利用率

这是 ThunderDuck Filter 算子的新性能基线。

---

*Generated by ThunderDuck V19 Benchmark Suite*
